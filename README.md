# PPO Implementation - Final Project

__Lynette Lau and Joshua Sanchez__ 

__Professor Qing-Shan Jia__

__Performance Evaluation and Optimization of Complex Systems, Fall 2021__ 

__Tsinghua University__

This is our group project code for the Final Project of PPO.

To run the code, please run train.py, test.py, and plot.py in terminal in Python in that order.

To change the hyperparameters, please reference the train.py file. 

Our partial results are stored under the results.txt.rtf file.

Please note some libraries might not be installed; when prompted, please use pip install to install packages. 

It is recommend you open a conda environment with PyTorch, and install libraries within that environment. 

Note that train.py may take 1 hour or more per seed for TRPO.  PPO implementations usually take ~15 minutes.

Code Reference: Robert Samoilescu - Policy Gradients: https://github.com/RobertSamoilescu/PolicyGradients
